# ‚úÖ ÌïÑÏöîÌïú Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò (Colab ÌôòÍ≤ΩÏóêÏÑú Ïã§Ìñâ Ïãú ÌïÑÏöî)
!pip install import_ipynb
!pip install umap-learn
!pip install imbalanced-learn
!pip install xgboost
!pip install scikeras


# ‚úÖ ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏûÑÌè¨Ìä∏
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, precision_score, recall_score, f1_score, precision_recall_curve
from sklearn.utils.class_weight import compute_class_weight
from imblearn.over_sampling import SMOTE
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, LeakyReLU
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import EarlyStopping
from umap import UMAP
from xgboost import XGBClassifier
from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression

# ‚úÖ Google Drive ÎßàÏö¥Ìä∏
from google.colab import drive
drive.mount('/content/drive')

# ‚úÖ Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°ú ÏÑ§Ï†ï
base_path = "/content/drive/MyDrive/hepscope/DN/"

# ‚úÖ ÌååÏùº Î°úÎìú Ìï®Ïàò (ÌååÏùºÏù¥ ÏóÜÏùÑ Í≤ΩÏö∞ Ïò§Î•ò Î∞©ÏßÄ)
def load_csv(file_name):
    file_path = os.path.join(base_path, file_name)
    if os.path.exists(file_path):
        return pd.read_csv(file_path).drop('Unnamed: 0', axis=1)
    else:
        raise FileNotFoundError(f"‚ùå ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {file_path}")

# ‚úÖ Train Data
train_aml_Malig = load_csv('train_Malig.csv')
train_aml_Normal = load_csv('train_Normal.csv')

train_aml_Normal['label'] = 0
train_aml_Malig['label'] = 1
train_aml_X = pd.concat([train_aml_Normal, train_aml_Malig]).reset_index(drop=True)
train_aml_Y = train_aml_X['label'].values
train_aml_X = train_aml_X.drop(columns='label')

# ‚úÖ Internal Validation Data (GSE116256)
val_aml_Normal = load_csv("val_internal_Normal.csv")
val_aml_Malig = load_csv("val_internal_Malig.csv")

val_aml_Normal['label'] = 0
val_aml_Malig['label'] = 1
val_aml_X = pd.concat([val_aml_Normal, val_aml_Malig]).reset_index(drop=True)
val_aml_Y = val_aml_X['label'].values
val_aml_X = val_aml_X.drop(columns='label')

# ‚úÖ External Validation Data (New External Dataset)
external_aml_Normal = load_csv("val_external_Normal.csv")
external_aml_Malig = load_csv("val_external_Malig.csv")

external_aml_Normal['label'] = 0
external_aml_Malig['label'] = 1
external_aml_X = pd.concat([external_aml_Normal, external_aml_Malig]).reset_index(drop=True)
external_aml_Y = external_aml_X['label'].values
external_aml_X = external_aml_X.drop(columns='label')

# ‚úÖ Îç∞Ïù¥ÌÑ∞ Ï†ïÍ∑úÌôî (StandardScaler Ï†ÅÏö©)
scaler = StandardScaler()
train_aml_X = scaler.fit_transform(train_aml_X)
val_aml_X = scaler.transform(val_aml_X)
external_aml_X = scaler.transform(external_aml_X)

# ‚úÖ Compute Class Weights
class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_aml_Y), y=train_aml_Y)
class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}
print("Computed class weights:", class_weight_dict)

# ‚úÖ PCA ÏãúÍ∞ÅÌôî (Train vs Validation Îç∞Ïù¥ÌÑ∞ Î∂ÑÌè¨ ÌôïÏù∏)
pca = PCA(n_components=2)
train_pca = pca.fit_transform(train_aml_X)
val_pca = pca.transform(val_aml_X)
external_pca = pca.transform(external_aml_X)

plt.figure(figsize=(8,6))
sns.scatterplot(x=train_pca[:,0], y=train_pca[:,1], label="Train", alpha=0.5)
sns.scatterplot(x=val_pca[:,0], y=val_pca[:,1], label="Internal Validation", alpha=0.5)
sns.scatterplot(x=external_pca[:,0], y=external_pca[:,1], label="External Validation", alpha=0.5)
plt.title("PCA Projection of Train vs Validation (Internal & External)")
plt.legend()
plt.show()

# ‚úÖ Define Optimized MLP Model
mlp_model = Sequential([
    Input(shape=(train_aml_X.shape[1],)),

    Dense(512, kernel_regularizer=l2(0.01)),
    BatchNormalization(),
    LeakyReLU(alpha=0.01),
    Dropout(0.4),

    Dense(256, kernel_regularizer=l2(0.01)),
    BatchNormalization(),
    LeakyReLU(alpha=0.01),
    Dropout(0.4),

    Dense(128, kernel_regularizer=l2(0.01)),
    BatchNormalization(),
    LeakyReLU(alpha=0.01),
    Dropout(0.4),

    Dense(1, activation='sigmoid')
])

# ‚úÖ Compile Model
mlp_model.compile(optimizer=Adam(learning_rate=0.0003),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])

# ‚úÖ Early Stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# ‚úÖ Train Model
history =  mlp_model.fit(train_aml_X, train_aml_Y,
              validation_data=(val_aml_X, val_aml_Y),
              epochs=20,
              batch_size=32,
              class_weight=class_weight_dict,
              callbacks=[early_stopping],
              verbose=1)

# ‚úÖ ÌïôÏäµ Í≥°ÏÑ† (Train Loss vs Validation Loss) ÏãúÍ∞ÅÌôî
plt.figure(figsize=(8,6))
plt.plot(history.history['loss'], label='Train Loss', color='blue')
plt.plot(history.history['val_loss'], label='Validation Loss', color='red')
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Train vs Validation Loss Curve")
plt.legend()
plt.show()

# ‚úÖ Predict
internal_pred = mlp_model.predict(val_aml_X, batch_size=32).flatten()
external_pred = mlp_model.predict(external_aml_X, batch_size=32).flatten()

# ‚úÖ PR Curve Í∏∞Î∞ò Threshold ÏµúÏ†ÅÌôî
precisions, recalls, thresholds = precision_recall_curve(external_aml_Y, external_pred)
f1_scores = 2 * (precisions * recalls) / (precisions + recalls)
optimal_threshold = thresholds[np.argmax(f1_scores)]
print("üîπ Optimal Threshold:", optimal_threshold)

# ‚úÖ ÏµúÏ†Å Threshold Ï†ÅÏö©
internal_res = [1 if res > optimal_threshold else 0 for res in internal_pred]
external_res = [1 if res > optimal_threshold else 0 for res in external_pred]

# ‚úÖ Performance Metrics
def print_metrics(y_true, y_pred, name):
    print(f"\nüìå {name} Performance")
    print(confusion_matrix(y_true, y_pred))
    print("Accuracy:", accuracy_score(y_true, y_pred))
    print("AUC:", roc_auc_score(y_true, y_pred))
    print("Precision:", precision_score(y_true, y_pred))
    print("Recall:", recall_score(y_true, y_pred))
    print("F1 Score:", f1_score(y_true, y_pred))

print_metrics(val_aml_Y, internal_res, "Internal Validation")
print_metrics(external_aml_Y, external_res, "External Validation (Optimized Threshold)")

# ‚úÖ Confusion Matrix ÏãúÍ∞ÅÌôî
def plot_confusion_matrix(y_true, y_pred, title, cmap):
    plt.figure(figsize=(5,5))
    sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt='d', cmap=cmap,
                xticklabels=["Normal", "Malig"], yticklabels=["Normal", "Malig"])
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title(title)
    plt.show()

plot_confusion_matrix(val_aml_Y, internal_res, "Confusion Matrix (Internal Validation)", "Blues")
plot_confusion_matrix(external_aml_Y, external_res, "Confusion Matrix (External Validation)", "Oranges")

# ‚úÖ Best Model Ï†ÄÏû•
model_path = os.path.join(base_path, "best_aml_prediction_mlp_model.h5")
mlp_model.save(model_path)
print(f"‚úÖ Best model saved at: {model_path}")
